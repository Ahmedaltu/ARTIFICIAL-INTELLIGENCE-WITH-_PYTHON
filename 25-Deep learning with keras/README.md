#Deep learning with keras. 

-----------------------------------
tf.keras.activations.relu 
The function returns 0 if it receives any negative input, but for any positive value x it returns that value back. >> https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu.  





-----------------------------------
tf.keras.activations.softmax >> https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax. 



----------------------------------
Normilizing data between 0 and 1


To normalize the values in a dataset to be between 0 and 1, you can use the following formula:

zi = (xi – min(x)) / (max(x) – min(x))
